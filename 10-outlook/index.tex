\chapter{Ausblick}
\label{chp:outlook}

\section{Veröffentlichungen}
\authors{\AB \and \DH}{\HM \and \DE}

\subsection{Liste der Veröffentlichungen} % Muss nach ``Fazit'' verschoben
% werden
In Rahmen der zweiten Hälfte des studentischen Projekts ist ein
Paper\cite{fidiuspaper} mit dem Titel \enquote{Intelligent Support
for Vulnerability Testing} als Bewerbung für die SecArt-Sicherheits-Konferenz
entstanden. Im Paper werden die Ideen und Ziele des \f-System und deren
bisheriger Status beschrieben und wie das \f-System Sicherheitsexperten bei
der Arbeit unterstützen kann. Das Paper wurde von der
SecArt 2011 angenommen und dort vorgestellt.

Neben der Teilnahme an der SecArt entstand im Zuge des Projekts die
EvasionDB, welche eine Komponente des
\f-Systems ist. Die EvasionDB ist im
Abschnitt~\ref{sec:idsevasion:evasiondb} ausführlich beschrieben und
wurde auf
Github\footnote{\url{https://github.com/fidius/fidius-evasiondb}} und
Rubygems\footnote{\url{https://rubygems.org/gems/fidius-evasiondb}}
veröffentlicht.

Um bekannte Schwachstellen aus einer eigenen Datenbank abrufbar zu
haben, wurde die CVE-DB, welche im Abschnitt~\ref{sec:cve-db}
beschrieben ist, entwickelt. Dieses Modul wurde ebenfalls auf
Github\footnote{\url{https://github.com/fidius/cvedb}} und
Rubygems\footnote{\url{https://rubygems.org/gems/fidius-cvedb}}
veröffentlicht.

Sowohl EvasionDB als auch CVE-DB wurden unter der Simplified BSD und GNU
GPLv2 Lizenz veröffentlicht.

Zusätzlich haben wir Verbesserungen für das \acr{msf} zum \acr{msf}-Projekt
beigetragen und sie wurden in die offizielle Version von \acr{msf} aufgenommen.
Bei diesen Verbesserungen handelte es sich einerseits um Fixes für mehrere
kleinere Fehler in \acr{msf}, die uns im Laufe des \f-Projektes aufgefallen sind.
Andererseits haben wir unsere Erweiterung des Lab-Plugins (siehe~\ref{lab})
um Unterstützung für \glos{virtualbox} auf der \acr{msf}-Mailingliste vorgestellt
und sie wurde auch in die offizielle Version von \acr{msf} integriert.
\footnote{\url{http://dev.metasploit.com/redmine/projects/framework/repository/revisions/11753}}

\subsection{Ausstehende Veröffentlichungen}

Im Laufe des Projekts entstanden weitere Komponenten, die sich bislang
noch in der Entwicklungsphase befinden, die mit etwas zusätzlichem
Aufwand veröffentlicht werden könnten. Zum einen wäre da Snortor, eine
Komponente die Snort-Regeln im- und exportieren kann, welche im
Abschnitt~\ref{snortor} beschrieben ist. Zum anderen wurden mehrere
\acr{msf}-Erweiterungen wie im Abschnitt~\ref{sub_sec:msf_plugins}
erläutert, entwickelt. Diese Erweiterungen könnten später dokumentiert
und veröffentlicht werden. Ebenso wurde die \acr{msf}-Erweiterung
\textit{lab}, mit der verschiedene Virtualisierungssysteme direkt aus
dem \acr{msf} kontrolliert werden können, um die Virtualisierer
VirtualBox und Qemu erweitert. VirtualBox wurde bereits veröffentlicht
und ist in das \acr{msf} von den Entwicklern aufgenommen worden. Bei
der Qemu-Steuerung steht die Veröffentlichung aus. Diese Erweiterung
wurde im Abschnitt~\ref{lab} näher erläutert.  Zuletzt könnte die
Veröffentlichung des \f-Systems als eigenständig lauffähige
Applikation in Betracht gezogen werden. Hierbei könnte das \f-System
in einer virtualisierten Umgebung eingerichtet und vorkonfiguriert
werden, so dass alle gängigen Virtualisierungssysteme dieses System
starten können.


\section{Künstliche Intelligenz}
\authors{\DK}{\DE \and \HM}
Da die Planmethoden nur unter kompletten oder nahezu kompletten
Wissensbasen funktionieren und das \verb#Neuronale Netz# nur Hosts
vorschlägt, aber keine Aktionen, denken wir, dass eine dritte Methode
eingeführt werden sollte.

Um online Aktionsketten die unter bestimmten Bedingungen zu einem Ziel
führen zu bestimmen, bietet sich \enquote{Reinforcement Learning}
\cite{mitchel} oder \verb#Bestärkendes Lernen# an.  Im
\verb#Bestärkenden Lernen#, führt der Agent Aktionen durch, die ihn
(seiner Meinung nach) näher an ein Ziel führen.  Für gut gewählte
Aktionen, also Aktionen nach denen der Agent näher am Ziel ist, wird
der Agent belohnt.  Um dies zu realisieren braucht der Agent eine
Evaluierungsfunktion. In unserem Fall könnte dies die \enquote{loudness} aus
der EvasionDB sein. Der Agent würde dann versuchen möglichst
\enquote{leise} zu bleiben und würde für \enquote{laute} Aktionen bestraft werden.
Dabei könnten auch Aktionen zum verschleiern genutzt werden, wie das
Warten zwischen Aktionen oder das Wechseln der IP- Adresse.  Die Ziele
des Agenten könnten weiterhin das Erkunden des Netzes sein (der Agent
wird für exploratives Verhalten belohnt) oder die Maximierung des
Wissens (der Agent wird für sammeln von Daten belohnt). Diese
Komponente kann mit Hilfe von \verb#Hidden Markov Modellen# oder
sog. \verb#Markov Ketten# implementiert werden.  Ein Testaufbau für
die Umsetzung könnte wie folgt aussehen.  Wir installieren mehrere
\gls{glos:nids} in einem Netz in unterschiedlichen aber gängigen
Konfigurationen. Dann wird der Agent in dem Netz Aktionen ausführen
und erhält Feedback über die \enquote{loudness} der Aktionen.  Dieser
Vorgang wird solange wiederholt, bis eine gewisse \enquote{loudness}
erreicht ist.  Somit kann in einem Testnetz der Agent trainiert werden
um in anderen Netzen unauffällig zu bleiben.

Eine weitere Möglichkeit der KI könnte sein den \enquote{contingent planner}
zu nutzen, um Angriffs-Vektoren auf ein Netz aufzudecken. In der AG-
Rechnernetze der Universität Bremen wird im Moment ein Ontologie
entwickelt, die das Rechnernetz des Fachbereichs 3 beschreibt. Aus
dieser Wissensdatenbank könnten mit Hilfe des Planers, mögliche
Angriffspunkte aufgedeckt werden.

